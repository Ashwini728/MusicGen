# -*- coding: utf-8 -*-
"""task_03.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IhYLDElrKHtTpl5jv_RhuDtwYSZIzXnc
"""

!pip install transformers torchaudio accelerate

from transformers import AutoProcessor, MusicgenForConditionalGeneration
import torch
import scipy.io.wavfile as wavfile

# Load the pre-trained MusicGen model
processor = AutoProcessor.from_pretrained("facebook/musicgen-small")
model = MusicgenForConditionalGeneration.from_pretrained("facebook/musicgen-small")


device = "cuda" if torch.cuda.is_available() else "cpu"
model.to(device)

# --- User input ---
user_mood = input("Enter the desired mood or genre (e.g., happy jazz, sad piano, energetic pop): ")

# --- Generate 20-second music ---
inputs = processor(
    text=[f"A 30-second {user_mood} instrumental music track"],
    padding=True,
    return_tensors="pt"
).to(device)

# Generate music
audio_values = model.generate(**inputs, max_new_tokens=512)

# Convert tensor to numpy and save as WAV file
audio = audio_values[0, 0].cpu().numpy()
output_path = f"generated_{user_mood.replace(' ', '_')}.wav"

# Save audio file (16kHz sample rate)
wavfile.write(output_path, rate=16000, data=audio)
print(f" 30-second {user_mood} music generated and saved as {output_path}")